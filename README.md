# Analyse des donn√©es NoSQL de GDELT
![image](https://github.com/user-attachments/assets/44604982-9484-47f5-bf76-42d21fbb1650)

****
Le projet GDELT est une base de donn√©es mondiale qui collecte, analyse et met √† jour en temps r√©el les √©v√©nements m√©diatiques mondiaux issus de millions de sources d‚Äôinformation dans plus de 100 langues.

****
# Les √©chantillons de GDELT travaill√©s
On se concentre sur deux bases de donn√©es :

## 1. **GDELT Events Database**  
   - Contient les **√©v√©nements g√©opolitiques** identifi√©s dans l‚Äôactualit√© (protestations, conflits, accords, etc.).
   - Champs utilis√©s :
     - `GlobalEventId`
     - `ActionGeo_CountryCode` (pays de l'√©v√©nement)
     - `EventDate`, `MonthYear`, `Year`
     - `MentionTranslationInfo` (langue de l‚Äôarticle)
     - `MentionTimeDate`
   - Utilisation :
     - Suivi des √©v√©nements par pays, date et langue
     - Analyse de relations bilat√©rales (ex : France ‚Äì Chine)


## 2. **Global Knowledge Graph (GKG)**  
   - Extrait des **entit√©s, th√®mes et sentiments** des articles d‚Äôactualit√©.
   - Champs utilis√©s :
     - `GkgRecordId`
     - `SourceCommonName` (nom du m√©dia)
     - `Themes`, `Persons`, `Locations`
     - `AverageTone` (tonalit√© moyenne)
     - `Date`, `MonthYear`, `Year`
   - Utilisation :
     - Analyse du contenu m√©diatique par source
     - Identification des sujets et personnalit√©s abord√©s
     - Calcul du ton moyen des articles
---
****



<img title="" src="objectif.png" alt="96741f3f-6a94-4881-afc8-8fe3203cbdd1" data-align="center" style="zoom:200%;">

***
# Objectif du point de vue informatique 
- Mettre en ≈ìuvre une architecture Big Data distribu√©e, r√©siliente et performante.
- Concevoir un syst√®me de stockage :
  - **Distribu√©**
  - **R√©silient** (capable de r√©sister √† la panne d‚Äôun n≈ìud)
  - **Performant** (rapide et robuste)
- R√©pondre √† une probl√©matique concr√®te :
  - Volume de donn√©es initiales (GDELT) : **> 100 Go**
  - Donn√©es √† stocker dans Cassandra : **> 5 Go**
  - R√©alisation de **4 requ√™tes analytiques sp√©cifiques**

# Pipeline de Donn√©es

- **T√©l√©chargement** depuis GDELT (~15 Go)
- **Filtrage & transformation** via Spark
- **Stockage final** dans Cassandra (~1.6 Go)
- **Suppression des donn√©es brutes**
- **Requ√™tes analytiques** via Zeppelin

***
# Architecture du cluster 
- **Spark** : Mode *HA* (High Availability) avec 2 Masters + Zookeeper
- **Cassandra** : Stockage distribu√© sur les 6 Workers
- **Zeppelin** : Install√© sur les 2 Masters comme interface d'analyse
- **Zookeeper** : 3 instances (2 Masters + 1 Worker) pour tol√©rance aux pannes

# D√©marche de configuration bri√®vement
## 1. Connexion au cluster

- Connexion SSH aux 8 machines fournies par l‚Äô√©cole :
```bash
ssh ubuntu@ip_server && ssh tp-hadoop-XX
```

- Cr√©ation de cl√©s SSH pour une interconnexion sans mot de passe
- Ajout des IPs dans le fichier `/etc/hosts` pour communication fluide
---

## 2. Installation des d√©pendances
#### Java 8
```bash
sudo apt-get install openjdk-8-jdk
```
Ajout de la variable d‚Äôenvironnement :
```bash
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64/jre
```

#### Python
```bash
sudo apt install python
```

---
## 3. Apache Cassandra (v3.11.3)

- Install√© sur les **6 Workers**
- Configuration du fichier `cassandra.yaml` :
  - `cluster_name`, `seed_provider`, `listen_address`, `rpc_address`
  - Distribution automatis√©e avec `scp` et script shell

- Lancement :
```bash
cd apache-cassandra-3.11.3 && bin/cassandra
nodetool status
```

---

## 4. Apache Spark (v2.3.2)

- Install√© sur les **8 machines**
- Mode de d√©ploiement : **Standalone** + configuration **HA** avec Zookeeper
- Fichiers configur√©s :
  - `spark-env.sh`, `spark-defaults.conf`, `slaves`
  - Connexion automatique √† Cassandra via Spark-Cassandra Connector

- Lancement :
```bash
cd spark-2.3.2-bin-hadoop2.7/sbin && ./start-all.sh
```

---

## 5. Apache Zookeeper (v3.5.6)

- Install√© sur **3 machines** (2 Masters + 1 Worker)
- Cr√©ation des dossiers `data/` et `logs/`, configuration du fichier `zoo.cfg`
- Fichier `myid` unique sur chaque n≈ìud
- Int√©gration dans `spark-env.sh` pour activer la **HA Spark** :
```bash
export SPARK_DAEMON_JAVA_OPTS="... -Dspark.deploy.recoveryMode=ZOOKEEPER ..."
```

---

## 6. Apache Zeppelin (v0.8.2)

- Install√© sur les **2 Masters**
- Configuration des fichiers :
  - `zeppelin-env.sh` ‚Üí Port personnalis√© (ex: 9090)
  - `zeppelin-site.xml` ‚Üí Adresse et port du serveur Zeppelin

- Lancement :
```bash
cd zeppelin-0.8.2-bin-all/bin && ./zeppelin-daemon.sh start
```
- Accessible via navigateur : `http://tp-hadoop-XX:9090`

---

## üß™ V√©rification finale

- Acc√®s Spark UI : `http://<master-ip>:8080` (ou `38080` en mode HA)
- Acc√®s Zeppelin : `http://<zeppelin-ip>:9090`
- Cassandra : v√©rification des n≈ìuds via `nodetool status`
---

## ‚úÖ R√©sum√©

- ‚úÖ Infrastructure **HA** avec Spark + Zookeeper
- ‚úÖ Stockage distribu√© et r√©silient via Cassandra
- ‚úÖ Requ√™tes interactives via Zeppelin
- ‚úÖ Scripts d‚Äôinstallation et configuration automatis√©s







